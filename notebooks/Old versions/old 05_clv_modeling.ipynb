{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database and loading data...\n",
      "Extracting transaction data for CLV modeling...\n",
      "Transaction data loaded. Shape: (405083, 4)\n",
      "Date range: 1993-01-01 00:00:00 to 1998-12-31 00:00:00\n",
      "Reference date for CLV calculation: 1998-12-31 00:00:00\n",
      "Could not load existing features. Will compute RFM manually.\n",
      "Created RFM features manually.\n",
      "Customer features loaded. Shape: (4500, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>recency_days</th>\n",
       "      <th>frequency</th>\n",
       "      <th>monetary_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>478</td>\n",
       "      <td>1597053.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>630267.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>1188498.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>175831.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>497029.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  recency_days  frequency  monetary_value\n",
       "0          2             0        478       1597053.5\n",
       "1          9             0        130        630267.9\n",
       "2         20             0        365       1188498.1\n",
       "3         27             0         62        175831.5\n",
       "4         45             0        130        497029.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data for CLV modeling...\n",
      "All required columns are available.\n",
      "\n",
      "Preparing RFM data for BG/NBD model...\n",
      "Prepared RFM data. Shape after filtering: (4500, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>recency_days</th>\n",
       "      <th>frequency</th>\n",
       "      <th>monetary_value</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3381.096444</td>\n",
       "      <td>2.599111</td>\n",
       "      <td>234.737778</td>\n",
       "      <td>3004.138321</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2839.605215</td>\n",
       "      <td>30.625054</td>\n",
       "      <td>126.849443</td>\n",
       "      <td>2043.285998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>452.472031</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1424.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>1246.368907</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2861.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>2495.455280</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4287.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>4330.144032</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13998.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>10687.383916</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          client_id  recency_days    frequency  monetary_value       T\n",
       "count   4500.000000   4500.000000  4500.000000     4500.000000  4500.0\n",
       "mean    3381.096444      2.599111   234.737778     3004.138321   730.0\n",
       "std     2839.605215     30.625054   126.849443     2043.285998     0.0\n",
       "min        1.000000      0.000000     9.000000      452.472031   730.0\n",
       "25%     1424.750000      0.000000   133.000000     1246.368907   730.0\n",
       "50%     2861.000000      0.000000   208.000000     2495.455280   730.0\n",
       "75%     4287.250000      0.000000   330.000000     4330.144032   730.0\n",
       "max    13998.000000    858.000000   675.000000    10687.383916   730.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for data issues...\n",
      "NaN values: 0\n",
      "Negative frequency values: 0\n",
      "Negative monetary values: 0\n",
      "Negative recency values: 0\n",
      "Negative T values: 0\n",
      "\n",
      "Fitting BG/NBD model for purchase frequency prediction...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Some values in recency vector are larger than T vector.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 222\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# Initialize and fit the BG/NBD model\u001b[39;00m\n\u001b[32m    221\u001b[39m bgf = BetaGeoFitter(penalizer_coef=\u001b[32m0.01\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[43mbgf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrfm_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfrequency\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrfm_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrecency_days\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrfm_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mT\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# Print model summary\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBG/NBD Model Parameters:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\carlo\\Documents\\4.DS\\CAT3.CustomerLVS\\venv\\Lib\\site-packages\\lifetimes\\fitters\\beta_geo_fitter.py:126\u001b[39m, in \u001b[36mBetaGeoFitter.fit\u001b[39m\u001b[34m(self, frequency, recency, T, weights, initial_params, verbose, tol, index, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m recency = np.asarray(recency)\n\u001b[32m    125\u001b[39m T = np.asarray(T)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[43m_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     weights = np.ones_like(recency, dtype=\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\carlo\\Documents\\4.DS\\CAT3.CustomerLVS\\venv\\Lib\\site-packages\\lifetimes\\utils.py:434\u001b[39m, in \u001b[36m_check_inputs\u001b[39m\u001b[34m(frequency, recency, T, monetary_value)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recency \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m T \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m np.any(recency > T):\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSome values in recency vector are larger than T vector.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(recency[frequency == \u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    436\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThere exist non-zero recency values when frequency is zero.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Some values in recency vector are larger than T vector."
     ]
    }
   ],
   "source": [
    "# 05_clv_modeling.ipynb\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lifetimes import BetaGeoFitter, GammaGammaFitter\n",
    "from lifetimes.utils import summary_data_from_transaction_data\n",
    "import pyodbc\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Define plot aesthetics\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Import custom feature engineering module\n",
    "# Make sure this file is in the same directory or adjust the import path\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from feature_engineering import get_database_connection\n",
    "\n",
    "# 1. Connect to the database and load the data\n",
    "print(\"Connecting to database and loading data...\")\n",
    "\n",
    "# Adjust connection string as needed\n",
    "connection_string = (\n",
    "    \"Driver={SQL Server};\"\n",
    "    \"Server=JUANCARLOSRUIZA;\"\n",
    "    \"Database=CzechBankingAnalysis;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")\n",
    "\n",
    "#1\n",
    "# Set a consistent reference date for all CLV calculations\n",
    "if 'date' in transactions.columns:\n",
    "    latest_transaction_date = transactions['date'].max()\n",
    "    # Add a small buffer to ensure all transactions are included\n",
    "    reference_date = latest_transaction_date + pd.Timedelta(days=1)\n",
    "else:\n",
    "    # If you don't have transaction data loaded, use a fixed date\n",
    "    reference_date = datetime(1998, 12, 31)  # Adjust based on your data\n",
    "\n",
    "print(f\"Using reference date for CLV calculations: {reference_date}\")\n",
    "\n",
    "# Use this reference date consistently throughout the notebook\n",
    "# when calculating recency and observation periods\n",
    "\n",
    "try:\n",
    "    conn = get_database_connection(connection_string)\n",
    "    \n",
    "    # Load customer features - you can either:\n",
    "    # Option 1: Load from CSV if already generated\n",
    "    if os.path.exists('../data/processed/banking_customer_features.csv'):\n",
    "        print(\"Loading pre-computed features from CSV...\")\n",
    "        customer_features = pd.read_csv('../data/processed/banking_customer_features.csv')\n",
    "    # Option 2: Generate features directly\n",
    "    else:\n",
    "        print(\"Extracting transaction data for CLV modeling...\")\n",
    "        \n",
    "        # Query to extract transaction data in the format needed for CLV modeling\n",
    "        transaction_query = \"\"\"\n",
    "        SELECT \n",
    "            d.client_id,\n",
    "            t.Trans_date AS date,\n",
    "            t.amount,\n",
    "            t.balance\n",
    "        FROM \n",
    "            Trans t\n",
    "        JOIN \n",
    "            Account a ON t.account_id = a.account_id\n",
    "        JOIN \n",
    "            Disposition d ON a.account_id = d.account_id\n",
    "        WHERE \n",
    "            d.type = 'OWNER'\n",
    "            AND t.Trans_type = 'PRIJEM'  -- Credit transactions (positive cash flow)\n",
    "        ORDER BY \n",
    "            d.client_id, t.Trans_date\n",
    "        \"\"\"\n",
    "        \n",
    "        transactions = pd.read_sql(transaction_query, conn)\n",
    "        \n",
    "        # Ensure date is in datetime format\n",
    "        transactions['date'] = pd.to_datetime(transactions['date'])\n",
    "        \n",
    "        # Fix: Set a reference date that's after all transactions\n",
    "        reference_date = datetime(1998, 12, 31)  # Adjust as needed based on your data\n",
    "        \n",
    "        print(f\"Transaction data loaded. Shape: {transactions.shape}\")\n",
    "        print(f\"Date range: {transactions['date'].min()} to {transactions['date'].max()}\")\n",
    "        print(f\"Reference date for CLV calculation: {reference_date}\")\n",
    "        \n",
    "        # Load existing features if available\n",
    "        try:\n",
    "            customer_features = pd.read_csv('../data/processed/banking_customer_features.csv')\n",
    "            print(\"Loaded existing customer features.\")\n",
    "        except:\n",
    "            print(\"Could not load existing features. Will compute RFM manually.\")\n",
    "            \n",
    "            # Create RFM summary manually\n",
    "            rfm_query = \"\"\"\n",
    "            WITH CustomerTransactions AS (\n",
    "                SELECT \n",
    "                    d.client_id,\n",
    "                    MAX(t.Trans_date) AS last_transaction_date,\n",
    "                    COUNT(t.trans_id) AS transaction_frequency,\n",
    "                    SUM(CASE WHEN t.Trans_type = 'PRIJEM' THEN t.amount ELSE 0 END) AS total_monetary_value\n",
    "                FROM \n",
    "                    Trans t\n",
    "                JOIN \n",
    "                    Account a ON t.account_id = a.account_id\n",
    "                JOIN \n",
    "                    Disposition d ON a.account_id = d.account_id\n",
    "                WHERE \n",
    "                    d.type = 'OWNER'\n",
    "                GROUP BY \n",
    "                    d.client_id\n",
    "            )\n",
    "            SELECT \n",
    "                client_id,\n",
    "                DATEDIFF(day, last_transaction_date, '1998-12-31') AS recency_days,\n",
    "                transaction_frequency AS frequency,\n",
    "                total_monetary_value AS monetary_value\n",
    "            FROM \n",
    "                CustomerTransactions\n",
    "            \"\"\"\n",
    "            \n",
    "            customer_features = pd.read_sql(rfm_query, conn)\n",
    "            print(\"Created RFM features manually.\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Database connection error: {e}\")\n",
    "    \n",
    "    # Fallback to using CSV data directly if database connection fails\n",
    "    try:\n",
    "        customer_features = pd.read_csv('../data/processed/banking_customer_features.csv')\n",
    "        print(\"Loaded customer features from CSV as fallback.\")\n",
    "    except:\n",
    "        print(\"Could not load data. Please check your database connection or ensure CSV files exist.\")\n",
    "        raise\n",
    "\n",
    "print(f\"Customer features loaded. Shape: {customer_features.shape}\")\n",
    "\n",
    "# Display first few rows of customer features\n",
    "display(customer_features.head())\n",
    "\n",
    "# 2. Prepare data for CLV modeling\n",
    "print(\"\\nPreparing data for CLV modeling...\")\n",
    "\n",
    "# Ensure we have the required columns for lifetimes package\n",
    "required_columns = ['client_id', 'recency_days', 'frequency', 'monetary_value']\n",
    "missing_columns = [col for col in required_columns if col not in customer_features.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"Warning: Missing required columns: {missing_columns}\")\n",
    "    print(\"Trying to calculate them from transaction data...\")\n",
    "    \n",
    "    # Load transaction data to calculate missing columns\n",
    "    transactions['date'] = pd.to_datetime(transactions['date'])\n",
    "    \n",
    "    # Convert to lifetimes format (frequency/recency format)\n",
    "    summary = summary_data_from_transaction_data(\n",
    "        transactions,\n",
    "        'client_id',\n",
    "        'date',\n",
    "        'amount',\n",
    "        observation_period_end=reference_date\n",
    "    )\n",
    "    \n",
    "    # Rename columns to match our convention\n",
    "    summary = summary.reset_index()\n",
    "    summary.columns = ['client_id', 'frequency', 'recency_days', 'T', 'monetary_value']\n",
    "    \n",
    "    # Recency in days instead of time units\n",
    "    summary['recency_days'] = summary['recency_days'].astype(int)\n",
    "    \n",
    "    # Use this as our customer features\n",
    "    customer_features = summary\n",
    "    print(\"Calculated RFM features from transactions.\")\n",
    "else:\n",
    "    print(\"All required columns are available.\")\n",
    "#2\n",
    "# Verify RFM calculations against raw transaction data\n",
    "if 'transactions' in locals():\n",
    "    # Sample a few customers to verify\n",
    "    sample_customers = rfm_data['client_id'].sample(min(5, len(rfm_data))).tolist()\n",
    "    \n",
    "    print(\"\\nVerifying RFM calculations for sample customers:\")\n",
    "    for client_id in sample_customers:\n",
    "        client_transactions = transactions[transactions['client_id'] == client_id]\n",
    "        \n",
    "        # Calculate metrics directly\n",
    "        last_purchase = client_transactions['date'].max()\n",
    "        recency = (reference_date - last_purchase).days\n",
    "        frequency = len(client_transactions) - 1  # -1 because first purchase isn't a repeat\n",
    "        monetary = client_transactions['amount'].mean()\n",
    "        \n",
    "        # Compare with rfm_data\n",
    "        rfm_row = rfm_data[rfm_data['client_id'] == client_id]\n",
    "        \n",
    "        print(f\"\\nClient ID: {client_id}\")\n",
    "        print(f\"Recency - Calculated: {recency}, In RFM data: {rfm_row['recency_days'].values[0]}\")\n",
    "        print(f\"Frequency - Calculated: {frequency}, In RFM data: {rfm_row['frequency'].values[0]}\")\n",
    "        print(f\"Monetary - Calculated: {monetary:.2f}, In RFM data: {rfm_row['monetary_value'].values[0]:.2f}\")\n",
    "\n",
    "# Prepare RFM data for BG/NBD model\n",
    "print(\"\\nPreparing RFM data for BG/NBD model...\")\n",
    "\n",
    "# Make a copy of the relevant columns\n",
    "rfm_data = customer_features[required_columns].copy()\n",
    "\n",
    "# Filter out rows with invalid values\n",
    "rfm_data = rfm_data[\n",
    "    (rfm_data['frequency'] > 0) &  # At least one repeat transaction\n",
    "    (rfm_data['monetary_value'] > 0)  # Positive monetary value\n",
    "]\n",
    "\n",
    "# Calculate average monetary value per transaction\n",
    "rfm_data['monetary_value'] = rfm_data['monetary_value'] / rfm_data['frequency']\n",
    "\n",
    "# Add the total time observation period (T)\n",
    "# Assuming the observation period is the same for all customers (e.g., 2 years)\n",
    "rfm_data['T'] = 365 * 2  # 2 years in days\n",
    "# If you have customer-specific tenure, you could use that instead\n",
    "if 'customer_tenure_days' in customer_features.columns:\n",
    "    rfm_data['T'] = customer_features['customer_tenure_days']\n",
    "\n",
    "print(f\"Prepared RFM data. Shape after filtering: {rfm_data.shape}\")\n",
    "\n",
    "# Display descriptive statistics\n",
    "display(rfm_data.describe())\n",
    "\n",
    "#3\n",
    "def validate_rfm_data(df):\n",
    "    \"\"\"Validate RFM data meets requirements for BG/NBD modeling\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    if (df['frequency'] <= 0).any():\n",
    "        issues.append(f\"Some frequency values are <= 0: {(df['frequency'] <= 0).sum()} records\")\n",
    "    \n",
    "    if (df['monetary_value'] <= 0).any():\n",
    "        issues.append(f\"Some monetary values are <= 0: {(df['monetary_value'] <= 0).sum()} records\")\n",
    "        \n",
    "    if (df['recency_days'] < 0).any():\n",
    "        issues.append(f\"Some recency values are negative: {(df['recency_days'] < 0).sum()} records\")\n",
    "        \n",
    "    if (df['T'] <= 0).any():\n",
    "        issues.append(f\"Some T values are <= 0: {(df['T'] <= 0).sum()} records\")\n",
    "        \n",
    "    if (df['recency_days'] > df['T']).any():\n",
    "        issues.append(f\"Some recency values exceed observation time T: {(df['recency_days'] > df['T']).sum()} records\")\n",
    "    \n",
    "    # Check for outliers\n",
    "    freq_q3 = df['frequency'].quantile(0.75)\n",
    "    freq_iqr = df['frequency'].quantile(0.75) - df['frequency'].quantile(0.25)\n",
    "    freq_outliers = df[df['frequency'] > freq_q3 + 3*freq_iqr]\n",
    "    \n",
    "    if len(freq_outliers) > 0:\n",
    "        issues.append(f\"Found {len(freq_outliers)} frequency outliers (> Q3 + 3*IQR)\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "# Validate the cleaned data\n",
    "issues = validate_rfm_data(rfm_data)\n",
    "\n",
    "if issues:\n",
    "    print(\"\\nData validation found issues:\")\n",
    "    for issue in issues:\n",
    "        print(f\"- {issue}\")\n",
    "    print(\"\\nContinuing with modeling, but these issues may affect results.\")\n",
    "else:\n",
    "    print(\"\\nRFM data validation passed! Data is ready for modeling.\")\n",
    "\n",
    "# Additional data quality check\n",
    "print(\"\\nRFM Data Summary Statistics:\")\n",
    "display(rfm_data[['frequency', 'recency_days', 'T', 'monetary_value']].describe())\n",
    "\n",
    "# Visualize distributions to check for potential issues\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(rfm_data['frequency'], kde=True)\n",
    "plt.title('Frequency Distribution')\n",
    "plt.xlabel('Frequency (# of repeat transactions)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(rfm_data['recency_days'], kde=True)\n",
    "plt.title('Recency Distribution')\n",
    "plt.xlabel('Recency (days)')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(rfm_data['T'], kde=True)\n",
    "plt.title('Observation Period (T) Distribution')\n",
    "plt.xlabel('Observation period (days)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(rfm_data['monetary_value'], kde=True)\n",
    "plt.title('Monetary Value Distribution')\n",
    "plt.xlabel('Monetary value (per transaction)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(\"\\nChecking for data issues...\")\n",
    "print(f\"NaN values: {rfm_data.isna().sum().sum()}\")\n",
    "print(f\"Negative frequency values: {(rfm_data['frequency'] <= 0).sum()}\")\n",
    "print(f\"Negative monetary values: {(rfm_data['monetary_value'] <= 0).sum()}\")\n",
    "print(f\"Negative recency values: {(rfm_data['recency_days'] < 0).sum()}\")\n",
    "print(f\"Negative T values: {(rfm_data['T'] <= 0).sum()}\")\n",
    "\n",
    "# After preparing the RFM data, add this code to fix the observation time issue\n",
    "\n",
    "# 1. Print the issue for diagnosis\n",
    "print(\"\\nDiagnosing recency vs T issue:\")\n",
    "problematic_records = rfm_data[rfm_data['recency_days'] > rfm_data['T']]\n",
    "print(f\"Found {len(problematic_records)} records where recency > T\")\n",
    "\n",
    "if len(problematic_records) > 0:\n",
    "    # Display a few examples of problematic records\n",
    "    print(\"\\nExample problematic records:\")\n",
    "    display(problematic_records.head())\n",
    "\n",
    "# 2. Fix the issue by ensuring T is always >= recency_days\n",
    "print(\"\\nFixing the recency vs T inconsistency...\")\n",
    "\n",
    "# Option 1: Set T to at least recency_days + 1 for all customers\n",
    "rfm_data['T'] = np.maximum(rfm_data['recency_days'] + 1, rfm_data['T'])\n",
    "\n",
    "# Option 2 (Alternative): Filter out problematic records\n",
    "# rfm_data = rfm_data[rfm_data['recency_days'] <= rfm_data['T']]\n",
    "\n",
    "# Verify the fix\n",
    "remaining_issues = rfm_data[rfm_data['recency_days'] > rfm_data['T']]\n",
    "print(f\"Remaining records with recency > T: {len(remaining_issues)}\")\n",
    "\n",
    "# 3. Ensure all values are positive and non-zero\n",
    "rfm_data = rfm_data[\n",
    "    (rfm_data['frequency'] > 0) &  \n",
    "    (rfm_data['monetary_value'] > 0) &\n",
    "    (rfm_data['recency_days'] >= 0) &\n",
    "    (rfm_data['T'] > 0)\n",
    "]\n",
    "\n",
    "print(f\"Final clean dataset shape: {rfm_data.shape}\")\n",
    "\n",
    "# 3. Fit BG/NBD model for purchase frequency prediction\n",
    "print(\"\\nFitting BG/NBD model for purchase frequency prediction...\")\n",
    "\n",
    "# Initialize and fit the BG/NBD model\n",
    "bgf = BetaGeoFitter(penalizer_coef=0.01)\n",
    "bgf.fit(\n",
    "    rfm_data['frequency'],\n",
    "    rfm_data['recency_days'],\n",
    "    rfm_data['T']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(\"BG/NBD Model Parameters:\")\n",
    "print(f\"r: {bgf.params_['r']:.4f}\")\n",
    "print(f\"alpha: {bgf.params_['alpha']:.4f}\")\n",
    "print(f\"a: {bgf.params_['a']:.4f}\")\n",
    "print(f\"b: {bgf.params_['b']:.4f}\")\n",
    "\n",
    "# 4. Fit Gamma-Gamma model for monetary value prediction\n",
    "print(\"\\nFitting Gamma-Gamma model for monetary value prediction...\")\n",
    "\n",
    "# Initialize and fit the Gamma-Gamma model\n",
    "ggf = GammaGammaFitter(penalizer_coef=0.01)\n",
    "ggf.fit(\n",
    "    rfm_data['frequency'],\n",
    "    rfm_data['monetary_value']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(\"Gamma-Gamma Model Parameters:\")\n",
    "print(f\"p: {ggf.params_['p']:.4f}\")\n",
    "print(f\"q: {ggf.params_['q']:.4f}\")\n",
    "print(f\"v: {ggf.params_['v']:.4f}\")\n",
    "\n",
    "# 5. Calculate CLV predictions\n",
    "print(\"\\nCalculating customer lifetime value...\")\n",
    "\n",
    "# Define time period for CLV prediction (e.g., 1 year)\n",
    "prediction_time = 365  # days\n",
    "\n",
    "# Predict future transactions over the prediction period\n",
    "predicted_purchases = bgf.predict(\n",
    "    prediction_time,\n",
    "    rfm_data['frequency'],\n",
    "    rfm_data['recency_days'],\n",
    "    rfm_data['T']\n",
    ")\n",
    "\n",
    "# Calculate expected average profit per transaction\n",
    "expected_avg_profit = ggf.conditional_expected_average_profit(\n",
    "    rfm_data['frequency'],\n",
    "    rfm_data['monetary_value']\n",
    ")\n",
    "\n",
    "# Calculate CLV for each customer\n",
    "clv = ggf.customer_lifetime_value(\n",
    "    bgf,\n",
    "    rfm_data['frequency'],\n",
    "    rfm_data['recency_days'],\n",
    "    rfm_data['T'],\n",
    "    prediction_time,\n",
    "    rfm_data['monetary_value'],\n",
    "    discount_rate=0.15  # Annual discount rate of 15%\n",
    ")\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "rfm_data['predicted_purchases_1yr'] = predicted_purchases\n",
    "rfm_data['expected_avg_profit'] = expected_avg_profit\n",
    "rfm_data['clv_1yr'] = clv\n",
    "\n",
    "# Merge back with original customer data\n",
    "clv_predictions = pd.merge(\n",
    "    customer_features[['client_id']],\n",
    "    rfm_data[['client_id', 'predicted_purchases_1yr', 'expected_avg_profit', 'clv_1yr']],\n",
    "    on='client_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values for customers that didn't have sufficient history\n",
    "clv_predictions = clv_predictions.fillna(0)\n",
    "\n",
    "# 6. Visualize CLV Distribution\n",
    "print(\"\\nVisualizing CLV distribution...\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# CLV distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(clv_predictions['clv_1yr'], bins=50, kde=True)\n",
    "plt.title('Customer Lifetime Value Distribution')\n",
    "plt.xlabel('CLV (Currency Units)')\n",
    "plt.ylabel('Number of Customers')\n",
    "\n",
    "# Expected purchases distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(clv_predictions['predicted_purchases_1yr'], bins=50, kde=True)\n",
    "plt.title('Predicted Purchases (1 Year)')\n",
    "plt.xlabel('Number of Purchases')\n",
    "plt.ylabel('Number of Customers')\n",
    "\n",
    "# Expected average profit distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(clv_predictions['expected_avg_profit'], bins=50, kde=True)\n",
    "plt.title('Expected Average Profit per Transaction')\n",
    "plt.xlabel('Profit per Transaction (Currency Units)')\n",
    "plt.ylabel('Number of Customers')\n",
    "\n",
    "# Correlation between CLV and expected purchases\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(\n",
    "    x='predicted_purchases_1yr',\n",
    "    y='clv_1yr',\n",
    "    data=clv_predictions,\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.title('CLV vs Predicted Purchases')\n",
    "plt.xlabel('Predicted Purchases (1 Year)')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Identify top customers by CLV\n",
    "print(\"\\nIdentifying top customers by CLV...\")\n",
    "\n",
    "# Find top 300 customers by predicted CLV\n",
    "top_customers = clv_predictions.sort_values('clv_1yr', ascending=False).head(300)\n",
    "\n",
    "print(f\"Top 300 customers CLV statistics:\")\n",
    "print(f\"Average CLV: {top_customers['clv_1yr'].mean():.2f}\")\n",
    "print(f\"Minimum CLV: {top_customers['clv_1yr'].min():.2f}\")\n",
    "print(f\"Maximum CLV: {top_customers['clv_1yr'].max():.2f}\")\n",
    "print(f\"Total predicted value: {top_customers['clv_1yr'].sum():.2f}\")\n",
    "\n",
    "# Compare with overall average\n",
    "average_clv = clv_predictions['clv_1yr'].mean()\n",
    "print(f\"Overall average CLV: {average_clv:.2f}\")\n",
    "print(f\"Top customers CLV is {top_customers['clv_1yr'].mean() / average_clv:.1f}x higher than average\")\n",
    "\n",
    "# 8. Analyze CLV by product portfolio\n",
    "print(\"\\nAnalyzing CLV by product portfolio...\")\n",
    "\n",
    "# Let's merge CLV data with product features\n",
    "if 'product_diversity_score' in customer_features.columns or 'product_diversity' in customer_features.columns:\n",
    "    # Determine which product diversity column is available\n",
    "    product_col = 'product_diversity_score' if 'product_diversity_score' in customer_features.columns else 'product_diversity'\n",
    "    \n",
    "    # Get relevant product columns\n",
    "    product_columns = ['client_id', product_col]\n",
    "    if 'loan_count' in customer_features.columns:\n",
    "        product_columns.extend(['loan_count', 'card_count', 'permanent_order_count'])\n",
    "    \n",
    "    # Merge CLV with product data\n",
    "    clv_product_data = pd.merge(\n",
    "        clv_predictions,\n",
    "        customer_features[product_columns],\n",
    "        on='client_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Create a figure for product analysis\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # CLV by product diversity\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.boxplot(x=product_col, y='clv_1yr', data=clv_product_data)\n",
    "    plt.title('CLV by Product Diversity')\n",
    "    plt.xlabel('Number of Product Types')\n",
    "    plt.ylabel('Customer Lifetime Value')\n",
    "    \n",
    "    # If we have detailed product counts\n",
    "    if 'loan_count' in clv_product_data.columns:\n",
    "        # CLV by loan count\n",
    "        plt.subplot(2, 2, 2)\n",
    "        sns.boxplot(x='loan_count', y='clv_1yr', data=clv_product_data)\n",
    "        plt.title('CLV by Loan Count')\n",
    "        plt.xlabel('Number of Loans')\n",
    "        plt.ylabel('Customer Lifetime Value')\n",
    "        \n",
    "        # CLV by card count\n",
    "        plt.subplot(2, 2, 3)\n",
    "        sns.boxplot(x='card_count', y='clv_1yr', data=clv_product_data)\n",
    "        plt.title('CLV by Card Count')\n",
    "        plt.xlabel('Number of Cards')\n",
    "        plt.ylabel('Customer Lifetime Value')\n",
    "        \n",
    "        # CLV by permanent order count\n",
    "        plt.subplot(2, 2, 4)\n",
    "        product_order_counts = clv_product_data[clv_product_data['permanent_order_count'] <= 5]  # Limit to avoid outliers\n",
    "        sns.boxplot(x='permanent_order_count', y='clv_1yr', data=product_order_counts)\n",
    "        plt.title('CLV by Permanent Order Count')\n",
    "        plt.xlabel('Number of Permanent Orders')\n",
    "        plt.ylabel('Customer Lifetime Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Product diversity data not available for analysis.\")\n",
    "\n",
    "# 9. Save results\n",
    "print(\"\\nSaving results...\")\n",
    "\n",
    "# Save CLV predictions to CSV\n",
    "output_dir = '../data/processed/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "clv_predictions.to_csv(f'{output_dir}customer_clv_predictions.csv', index=False)\n",
    "top_customers.to_csv(f'{output_dir}diamond_customers.csv', index=False)\n",
    "\n",
    "# Save the models for future use\n",
    "models_dir = '../models/'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "joblib.dump(bgf, f'{models_dir}bg_nbd_model.pkl')\n",
    "joblib.dump(ggf, f'{models_dir}gamma_gamma_model.pkl')\n",
    "\n",
    "# Save model parameters in a more readable format\n",
    "model_params = {\n",
    "    'bg_nbd': {\n",
    "        'r': bgf.params_['r'],\n",
    "        'alpha': bgf.params_['alpha'],\n",
    "        'a': bgf.params_['a'],\n",
    "        'b': bgf.params_['b']\n",
    "    },\n",
    "    'gamma_gamma': {\n",
    "        'p': ggf.params_['p'],\n",
    "        'q': ggf.params_['q'],\n",
    "        'v': ggf.params_['v']\n",
    "    },\n",
    "    'metadata': {\n",
    "        'creation_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "        'prediction_time_days': prediction_time,\n",
    "        'discount_rate': 0.15\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f'{models_dir}clv_model_params.json', 'w') as f:\n",
    "    json.dump(model_params, f, indent=4)\n",
    "\n",
    "print(\"CLV predictions and models saved successfully.\")\n",
    "\n",
    "# 10. Add CLV data to our main feature set\n",
    "print(\"\\nMerging CLV predictions with feature dataset...\")\n",
    "\n",
    "# Merge CLV predictions with existing features\n",
    "customer_features_with_clv = pd.merge(\n",
    "    customer_features,\n",
    "    clv_predictions,\n",
    "    on='client_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Save the enhanced dataset\n",
    "customer_features_with_clv.to_csv(f'{output_dir}customer_features_with_clv.csv', index=False)\n",
    "\n",
    "print(\"Enhanced customer feature set with CLV saved successfully.\")\n",
    "print(f\"Final dataset shape: {customer_features_with_clv.shape}\")\n",
    "\n",
    "# Summary and conclusions\n",
    "print(\"\\n=== CLV Modeling Summary ===\")\n",
    "print(f\"Total customers analyzed: {len(clv_predictions)}\")\n",
    "print(f\"Customers with positive CLV: {(clv_predictions['clv_1yr'] > 0).sum()}\")\n",
    "print(f\"Average predicted purchases (1 year): {clv_predictions['predicted_purchases_1yr'].mean():.2f}\")\n",
    "print(f\"Average expected profit per transaction: {clv_predictions['expected_avg_profit'].mean():.2f}\")\n",
    "print(f\"Average customer lifetime value (1 year): {clv_predictions['clv_1yr'].mean():.2f}\")\n",
    "print(f\"Total portfolio value (1 year): {clv_predictions['clv_1yr'].sum():.2f}\")\n",
    "print(f\"Value concentrated in top 300 customers: {top_customers['clv_1yr'].sum() / clv_predictions['clv_1yr'].sum() * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Use CLV predictions for customer segmentation\")\n",
    "print(\"2. Develop targeted strategies for high-value customers\")\n",
    "print(\"3. Identify factors that correlate with higher CLV\")\n",
    "print(\"4. Create churn prediction models to protect high-value customers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
